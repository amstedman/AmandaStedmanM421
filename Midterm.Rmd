
---
output:
  html_document:
    theme: united
title: "Fall 2021 - Math 421 - Midterm"
---

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# {.tabset}

## Instruction

The midterm has two components: the Rmarkdown notebook (html) and the presentation.  We will do the presentation in class. Post both the notebook and the presentation on your Github page. 

**The notebook:** The notebook should be created using `rmarkdown` (like other assignments). The notebook should have a title. It should have a table of content (TOC form) or in a tab form. Here are the samples Rmarkdown for [TOC form](fa2021_midterm_toc.Rmd) and [tab form](fa2021_midterm_tab.Rmd)


**The Presentation:** Present your results in 5-10 minutes. To make the presentation using Rmarkdown, do the follows: 

    - In Rstudio -> File -> New File -> R markdown
    
    - In the left panel, click to Presentation -> Click OK
    
    - Now you have an Rmarkdown that can be knitted to be a html presentation 

- You can also use borrow a template of our class slides presentations. For example, [this slide](https://bryantstats.github.io/math421/slides/6_viz_fa21_2.html) has this [Rmarkdown](https://bryantstats.github.io/math421/slides/6_viz_fa21_2.Rmd)    

- You do not need to rerun all the codes for the presentation. For example, to show the model comparison, you just need to show the image of the model comparison instead of running all the models again.
    
- To inset an image in a slide, use  `![](image.png)`

- To turn off message and warning of a code cell, use:  `{r, message=FALSE, warning=FALSE}` for the cell. 

**What to present**:

  - Present Part 2 - Visualization
  
  - Present Question Question 4, 5 and 6 in Part 3.  
  
  - Present any errors/challenges you run into and how you fix/overcome them. 

**Data:**  

The data for the mid-term project is the Rhode Island Department of Health Hospital Discharge Data.  Each row of the data presents a patient. 

Link: https://drive.google.com/open?id=15QNBf6YYKocK2nNIfpKDer58kQnCPNZJ 

-------

## I. Data Wranggling

1. Download the data file `hdd0318cy.sas7bdat`.  

2. Use `read_sas` in library `haven` to read the data. 
```{r}
library(haven)
df <- read_sas('hdd0318cy.sas7bdat')
```
    
3. Filter the data to have only patients of the year 2018 (`yod==2018`)
```{r}
library(tidyverse)
df <- df %>% filter(yod==18)
```
    
4. Select to work with only following variables: 

```{r, eval=FALSE}
                     df <- df %>% select("yod", "payfix","pay_ub92","age",  
                      "sex","raceethn","provider","moa", 
                      "yoa","mod","admtype", "asource" , 
                      "preopday" ,"los", "service" , "icu","ccu",    
                      "dispub92", "payer"  ,"drg","trandb", 
                      "randbg","randbs","orr", "anes","seq",   
                      "lab","dtest", "ther","blood","phar", 
                      "other","patcon","bwght","total","tot" ,  
                      "ecodub92","b_wt","pt_state","diag_adm","ancilar" ,
                      "campus","er_fee","er_chrg","er_mode","obs_chrg",
                      "obs_hour","psycchrg","nicu_day")
```
 

*Notice*:  You may want to save the current data to your computer for easy access later.  To save the data file use `write_csv(df, 'midterm.csv')`, for example.  

5. What are variables that have missing values?
```{r}
df <- read_csv('m421midterm.csv')
```
```{r}
colSums(is.na(df))
```
 
6. Remove all variables with missing values
```{r}
df <- df %>% select(-payfix, -raceethn, -admtype, -asource, -preopday, -bwght, -ecodub92, -pt_state, -diag_adm, -er_mode, -obs_hour, -nicu_day)
```
 
7. Refer to the data description in the file `HDD2015-18cy6-20-19.docx`, which variable recording the month of admission?, which variable recording the month of discharge?
```{r}
#MOA represents month of admission and MOD represents month of discharge#
```

8. Which month admitted the most number of patients? Which month admitted the most number of male patients?
```{r}
table(df$moa)
d <- df %>% filter(sex==1)
table(df$moa)
```

9. Which month has the most number of teenage female patients?
```{r}
 d1 <- df %>% filter(sex==2, age==c(13:19))
table(d1$moa)
```

10. Which provider has the most number of female patients in October? 
```{r}
d2 <- df %>% filter(sex==2)
table(d2$provider)
```

11. Is female patients older than male patients, on average? 
```{r}
mean(d$age)
mean(d2$age)
##Male patients are older on average##
```

12. Calculate the average age of patients by months. Which month has the oldest patients on average age?
```{r}
df %>% group_by(moa) %>% summarise(mean(age))
##January has the oldest patients according to the average##
```

13. What is the name of the provider that has the highest total charge?
```{r}
df %>% group_by(provider) %>% summarise(sum(tot))
##Rhode Island Hospital has highest total charge##
```

14. What is the name of the provider that has the least total charge for teenage male on average?
```{r}
df %>% group_by(provider) %>% filter(sex==1, age == c(13,14,15,16,17,18,19)) %>% summarise(sum(tot))
```

15. Calculate the length of stays by provider.  Which provider has the longest length of stays on average?
```{r}
df %>% group_by(provider) %>% summarise(mean(los))
```

16. On average, how much a 20 year-old male get charged for staying 1 day?
```{r}
df %>% filter(los==1, age==20, sex==1) %>% summarise(mean(tot))
```

17. Write a paragraph to summarize the section and give your comments on the results. 
```{r}
## First, I learned that the average age for males and females are virtually the same, they are off by about 1 year. Provider 7215 (Bradley Hospital) had the longest average length of stay. This surprised me because it is a hospital for very specific needs (pediatric psychology), as opposed to Rhode Island Hospital, which treats many different ages and types of issues. Rhode Island Hospital (7205) also had the largest total cost, which was unsurprising given how large the hospital is compared to the others. ## 
```

-------

## II. Data Visualization

Continue with the data from part I. 
```{r}
library(ggplot2)
```

1. Provides at least 10 meaningful plots. Comments on the plots. All plots should have title, caption, appropriate labels on x and y-axis
```{r}
df %>% filter(sex==2) %>% ggplot()+geom_histogram(mapping = aes(x = age)) + labs(x = 'Age', y = 'Number of Patients', title = 'Age Distribution of Women', caption = 'There is a spike of hospitalized women around age 30')
```
```{r}
df$sex = factor(df$sex)
df %>% filter(sex %in% c(1,2)) %>% ggplot()+geom_bar(aes(x=sex, fill = sex)) + labs(x = 'Sex', y = 'Number of Patients', title = 'Number of Patients by Sex', caption = 'There are significantly more female patients than male')
```
```{r}
d3 <- df %>% filter(sex %in% c(1,2), los %in% c(1,10))
d3$sex = factor(d3$sex)
d3 %>% ggplot() + geom_density(mapping = aes(x = los, color = sex))
```
```{r}
d4 <- df %>% filter(age %in% c(13,14,15,16,17,18,19))
d4$provider = factor(d4$provider)
df %>% ggplot() + geom_bar(aes(x=provider)) + labs(x = 'Provider', y = 'Number of Teenage Patients', title = 'Number of Teenage Patients by Providers', caption = 'RIH, Miriam, and Women and Infants had the most number of teenage patients')
```
```{r}
df$provider = factor(df$provider)
df %>% filter(age %in% c(10:25), provider %in% c(7215,7216)) %>% ggplot() + geom_bar(aes(x = age, fill = provider)) + labs(x = 'Patient Age', y = 'Number of patients', title = 'Patients aged 10-25 at Bradley vs. Butler', caption = 'More younger patients seen at Bradley')
```
```{r}
df %>% filter(campus==4) %>% ggplot() + geom_density(aes(x=age)) + labs(x = 'Age', y = 'Density', title = 'density of Hasbro patients by age', caption = 'There is a peak around age 16')
```
```{r}
df$sex = factor(df$sex)
df %>% filter(campus==4) %>% ggplot() + geom_density(aes(x=age, color = sex)) + labs(x = 'Age', y = 'Density', title = 'density of Hasbro patients by age', caption = 'After age 10, a larger proportion of females are hospitalized')
```
```{r}
df$age = factor(df$age)
df %>% filter(provider==7215, age %in% c(5:10)) %>% ggplot() + geom_line(aes(x=los, y=tot, color = age)) + labs(x = 'Length of Stay', y = 'Total Cost', title = 'Length of Stay vs. Total Cost at Bradley Hospital', caption = 'Only ages 9 and 10 had anyone stay past 100 days')
```
```{r}
df$provider = factor(df$provider)
df %>% filter(sex==2, age %in% c(28:32)) %>% ggplot() + geom_bar(aes(x=provider, fill=provider)) + labs(x = 'provider', y='Count', title='Providers for Women Aged 28-32', caption = 'Women and Infants by far the most women in this age group')
```
```{r}
df %>% filter(sex %in% c(1,2), tot<=100000) %>% ggplot() + geom_boxplot(aes(x = tot, color = sex)) + labs(x = 'Total Cost', title = 'Measure of total cost by Sex', caption = 'The means of total cost is not very dependent on sex')
```

2. Make an animation plot. 
```{r}
library(gifski)
library(gganimate)
library(lubridate)
```
```{r}
df6 <- df %>% filter(campus==4|campus==3) %>% group_by(moa, campus) %>% summarise(mean = mean(los)) %>% mutate(rank=rank(-mean))
p6 <- df6 %>% ggplot(aes(y=factor(rank), x=mean, group=campus, fill = campus)) + geom_col() + transition_states(moa) + labs(x = 'length of stay', title = 'Month: {closest_state}')
animate(p6, n=100, fps=20)
```

3. Write a paragraph to summarize the section and give your comments on the results. 
```{r}
## First, with the animation plot, I discovered that Rhode Island Hospital's main campus consistently had a longer length of stay than Hasbro Children's Hospital. Next, among females, there was a major spike in hospital admissions around age 30, which I assume is because 30 is one of the most common ages to have children. Lastly, there was a significant increase in hospitalizations at the children's hospital around age 15 among both genders. ## 
```

-------

## III. Predictive Models

Continue with the data from part I. Use the follows as the target and input variables: 
```{r}
library(tidyverse)
df1 <- read_csv('m421midterm.csv')
```


*Target Variable*: Create the target variable taking value of 

  - `low` if the total charge of a patient (`tot`) is smaller than the median of the total charge, and

  - `high` otherwise. 
```{r}
median(df1$tot)
df1$target <- case_when(df1$tot<21854 ~ 'low', df1$tot>=21854 ~ 'high')
```

*Input Variables*:

  - "age","sex","raceethn","provider","moa","mod","admtype","campus", 'los'
```{r}
df1 <- df1 %>% select("target", "age", "sex","provider", "moa","mod","raceethn", "admtype", "campus", "los" )
names(df1)[1] <- 'target'
```
```{r}
df1 <- drop_na(df1, age, sex, raceethn, moa, mod, campus, los, target)
```

-------

1. Use `filter` function to filter out rows where `raceethn==''` or `admtype==''`. Make sure all the categorical variables are factor, numeric variables are numeric. Set Training : Testing Split = 10 : 90 
```{r}
df1 <- df1 %>% filter(admtype==1|admtype==2)
df1$sex = factor(df1$sex)
df1$raceethn = factor(df1$raceethn)
df1$provider = factor(df1$provider)
df1$campus = factor(df1$campus)
df1$admtype=factor(df1$admtype)
df1$target=factor(df1$target)
```
```{r}
library(caret)
set.seed(2020)
splitIndex1 <- createDataPartition(df1$target, p=.1, list=FALSE)
df1_train <- df1[splitIndex1,]
df1_test <- df1[-splitIndex1,]
```

2. Train a decision tree using `rpart`.  Plot the decision tree. Plot the variable importance ranked by the tree. 
```{r}
library(rpart)
tree_model1 <- rpart(target ~ ., data=df1_train, control=rpart.control(maxdepth = 3))
library(rattle)
fancyRpartPlot(tree_model1)
```

3. Using caret for this question. Set `Training Control` to be: Use Cross-Validation of 5 folds across all models.  Train & tune at least 3 different models (i.e. three different values for `method=` in the train function of caret).  Plot the hyper-parameter tuning plots for each model. 
```{r}
trControl = trainControl(method = "cv", number = 5)
tuneGrid = expand.grid(mtry = 1:5)
forest_rf <- train(target~., data=df1_train, method = "rf", trControl = trControl, tuneGrid = tuneGrid)
plot(forest_rf)
```
```{r}
trControl = trainControl(method = "cv", number = 5)
tuneGrid = expand.grid(mstop = 1:5, prune = 5)
forest_glm <- train(target~., data=df1_train, method = "glmboost", trControl = trControl, tuneGrid = tuneGrid)
plot(forest_glm)
```
```{r}
trControl = trainControl(method = "cv", number = 5)
tuneGrid = expand.grid(mfinal = 5, maxdepth = 1:5)
forest_ada <- train(target~., data=df1_train, method = "AdaBag", trControl = trControl, tuneGrid = tuneGrid)
plot(forest_ada)
```

4. Plot the comparison of the models in 3. 
```{r}
results <- resamples(list('Random Forest' = forest_rf,
                          'GLM' = forest_glm,
                          'ADA'= forest_ada))
bwplot(results)
```

5. What is your final selection for the model? Test the accuracy of your final model on the test data. 
```{r}
## the random forest is my final selection because it has the highest accuracy and kappa ##
pred <- predict(forest_rf, df1_test)
cm <- confusionMatrix(data = pred, reference = df1_test$target, positive = "high")
cm$overall[1]
```

6. Create another `target` variable (binary), decide the input variables and redo 1 to 5. 
```{r}
library(tidyverse)
df1 <- read_csv('m421midterm.csv')
median(df1$los)
df1$target <- case_when(df1$los<3 ~ 'low', df1$los>=3 ~ 'high')
df1 <- df1 %>% select("target", "age", "sex","provider", "moa","mod","raceethn", "admtype", "campus", "tot" )
names(df1)[1] <- 'target'
df1 <- drop_na(df1, age, sex, raceethn, moa, mod, campus, tot, target)
df1 <- df1 %>% filter(admtype==1|admtype==2)
df1$sex = factor(df1$sex)
df1$raceethn = factor(df1$raceethn)
df1$provider = factor(df1$provider)
df1$campus = factor(df1$campus)
df1$admtype=factor(df1$admtype)
df1$target=factor(df1$target)
library(caret)
set.seed(2020)
splitIndex1 <- createDataPartition(df1$target, p=.1, list=FALSE)
df1_train <- df1[splitIndex1,]
df1_test <- df1[-splitIndex1,]
```
```{r}
library(rpart)
tree_model1 <- rpart(target ~ ., data=df1_train, control=rpart.control(maxdepth = 3))
library(rattle)
fancyRpartPlot(tree_model1)
```
```{r}
trControl = trainControl(method = "cv", number = 5)
tuneGrid = expand.grid(mtry = 1:5)
forest_rf1 <- train(target~., data=df1_train, method = "rf", trControl = trControl, tuneGrid = tuneGrid)
plot(forest_rf1)
```
```{r}
trControl = trainControl(method = "cv", number = 5)
tuneGrid = expand.grid(mstop = 1:5, prune = 5)
forest_glm1 <- train(target~., data=df1_train, method = "glmboost", trControl = trControl, tuneGrid = tuneGrid)
plot(forest_glm1)
```
```{r}
trControl = trainControl(method = "cv", number = 5)
tuneGrid = expand.grid(mfinal = 5, maxdepth = 1:5)
forest_ada1 <- train(target~., data=df1_train, method = "AdaBag", trControl = trControl, tuneGrid = tuneGrid)
plot(forest_ada1)
```
```{r}
results <- resamples(list('Random Forest' = forest_rf1,
                          'GLM' = forest_glm1,
                          'ADA'= forest_ada1))
bwplot(results)
```

```{r}
## the random forest is my final selection because it has the highest accuracy and kappa ##
pred1 <- predict(forest_rf1, df1_test)
cm1 <- confusionMatrix(data = pred1, reference = df1_test$target, positive = "high")
cm$overall[1]
```

7. Write a paragraph to summarize the section and give your comments on the results. 
```{r}
## Overall, with both targets, I was not super happy with the results as the accuracies for the best model of both were only around 82%. The best model for both targets was the random forest. Ideally, I would have liked this to have been higher. My glm boost for the los target proved to be the least helpful because the accuracy of cross validation does not change with an increase in iterations. For both targets, the glms had the lowest accuracy. The Adabag models for both were very close behind the forest models in terms of accuracy and kappa, but were slightly less accurate.    
```

-------